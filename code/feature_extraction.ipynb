{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUZeKivKX8B0dORWE15GDD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5rQwsXFn95Wa"},"outputs":[],"source":["%pip install easyocr\n","\n","import os\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing import image\n","from skimage.feature import hog\n","from skimage.feature import local_binary_pattern\n","import easyocr\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from imutils.object_detection import non_max_suppression\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","CROPS_DIR = \"organized_crops\"\n","LABELS_DIR = \"runs/detect/exp/labels/\"\n","TEXT_FEATURES_FILE = \"text_features.npy\"\n","# Text Detection Parameters\n","INPUT_WIDTH = 320\n","INPUT_HEIGHT = 320\n","CONFIDENCE_THRESHOLD = 0.6\n","NMS_THRESHOLD = 0.5\n","\n","# load ResNet50 model\n","base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n","model = Model(inputs=base_model.input, outputs=base_model.output)\n","\n","# Load Pre-trained EAST Detector\n","net = cv2.dnn.readNet(\"/content/drive/MyDrive/Object_Recognition/frozen_east_text_detection.pb\")\n","\n","def read_image(image_path):\n","    img = cv2.imread(image_path)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    return img, gray\n","\n","def cnn_extract_features(image_path):\n","    img = image.load_img(image_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n","    features = model.predict(img_array)\n","    return features.flatten()\n","\n","def extract_color_histogram(image):\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    # calculate 3D Histogram (H,S,V)\n","    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256]) #(H:0-180, S:0-256, V:0-256)\n","    hist = cv2.normalize(hist, hist).flatten()\n","    return hist\n","\n","def extract_shape_features(gray_image):\n","    image = cv2.resize(gray_image, (128, 128))  # Normalize size for consistency\n","    fd, _ = hog(image, orientations=8, pixels_per_cell=(8, 8),\n","                cells_per_block=(2, 2), visualize=True, feature_vector=True)\n","    return fd\n","\n","def extract_texture_features(gray_image):\n","    # Gabor Filter\n","    gabor_kernel = cv2.getGaborKernel((21, 21), 5.0, np.pi/4, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n","    filtered_img = cv2.filter2D(gray_image, cv2.CV_8UC3, gabor_kernel)\n","    # Local Binary Patterns (LBP)\n","    lbp = local_binary_pattern(gray_image, P=24, R=3, method=\"uniform\")\n","\n","    return np.hstack([filtered_img.mean(), lbp.flatten()[:256]])  # Limit feature vector size\n","\n","def extract_spatial_features():\n","    spatial_features = {}\n","\n","    for label_file in os.listdir(LABELS_DIR):\n","        if label_file.endswith(\".txt\"):\n","            file_path = os.path.join(LABELS_DIR, label_file)\n","            base_name = label_file.replace(\".txt\", \"\")\n","\n","            with open(file_path, \"r\") as f:\n","                for index, line in enumerate(f.readlines(), start=1):\n","                    data = line.strip().split()\n","                    x_center, y_center, width, height = map(float, data[1:])\n","                    if index == 1:\n","                      cropped_image_name = f\"{base_name}.jpg\"\n","                    else:\n","                      cropped_image_name = f\"{base_name}{index}.jpg\"\n","                    dist_to_center = np.sqrt((x_center - 0.5) ** 2 + (y_center - 0.5) ** 2)\n","                    spatial_features[cropped_image_name] = [x_center, y_center, width, height, dist_to_center]\n","\n","    np.save(\"spatial_features.npy\", spatial_features)\n","    print(\"Save successfullt to spatial_features.npy\")\n","\n","\n","def decode_predictions(scores, geometry):\n","    \"\"\"\n","    Decode the EAST model's output into bounding boxes.\n","    \"\"\"\n","    rows, cols = scores.shape[2:4]\n","    rects = []\n","    confidences = []\n","\n","    for y in range(rows):\n","        for x in range(cols):\n","            if scores[0, 0, y, x] < CONFIDENCE_THRESHOLD:\n","                continue\n","\n","            # Extract geometries\n","            offset_x, offset_y = x * 4.0, y * 4.0\n","            angle = geometry[0, 4, y, x]\n","            cos, sin = np.cos(angle), np.sin(angle)\n","            h, w = geometry[0, 0, y, x], geometry[0, 1, y, x]\n","\n","            end_x = int(offset_x + (cos * w) + (sin * h))\n","            end_y = int(offset_y - (sin * w) + (cos * h))\n","            start_x = int(end_x - w)\n","            start_y = int(end_y - h)\n","\n","            rects.append((start_x, start_y, end_x, end_y))\n","            confidences.append(scores[0, 0, y, x])\n","\n","    return rects, confidences\n","\n","def detect_text_east(image_path):\n","    \"\"\"\n","    Apply EAST text detection on an input image.\n","    \"\"\"\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        raise FileNotFoundError(f\"Error: Image file '{image_path}' not found or unable to load!\")\n","\n","    orig = image.copy()\n","    h, w = image.shape[:2]\n","    ratio_w, ratio_h = w / INPUT_WIDTH, h / INPUT_HEIGHT\n","\n","    # Resize image for the EAST model\n","    blob = cv2.dnn.blobFromImage(image, 1.0, (INPUT_WIDTH, INPUT_HEIGHT),\n","                                 (123.68, 116.78, 103.94), swapRB=True, crop=False)\n","    net.setInput(blob)\n","\n","    # Get EAST outputs\n","    scores, geometry = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"])\n","\n","    # Decode predictions\n","    rects, confidences = decode_predictions(scores, geometry)\n","    boxes = non_max_suppression(np.array(rects), probs=confidences, overlapThresh=NMS_THRESHOLD)\n","\n","    # Scale boxes back to original image size\n","    results = []\n","    for (start_x, start_y, end_x, end_y) in boxes:\n","        start_x, start_y, end_x, end_y = (int(start_x * ratio_w), int(start_y * ratio_h),\n","                                          int(end_x * ratio_w), int(end_y * ratio_h))\n","        results.append((start_x, start_y, end_x, end_y))\n","\n","        # Ensure integer coordinates\n","        cv2.rectangle(orig, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n","\n","    return results\n","\n","def merge_overlapping_boxes(boxes, iou_threshold=0.3):\n","    \"\"\"\n","    Merge overlapping bounding boxes based on IoU (Intersection over Union).\n","    \"\"\"\n","    if len(boxes) == 0:\n","        return []\n","\n","    # Convert to NumPy array\n","    boxes = np.array(boxes)\n","\n","    # Sort boxes by x1 (left) coordinate\n","    boxes = boxes[np.argsort(boxes[:, 0])]\n","\n","    merged_boxes = []\n","    while len(boxes) > 0:\n","        # Take the first box\n","        x1, y1, x2, y2 = boxes[0]\n","        boxes = boxes[1:]\n","\n","        # Check overlap with other boxes\n","        indices_to_remove = []\n","        for i, (nx1, ny1, nx2, ny2) in enumerate(boxes):\n","            iou = compute_iou((x1, y1, x2, y2), (nx1, ny1, nx2, ny2))\n","            if iou > iou_threshold:  # Merge if overlap is high\n","                x1, y1 = min(x1, nx1), min(y1, ny1)\n","                x2, y2 = max(x2, nx2), max(y2, ny2)\n","                indices_to_remove.append(i)\n","\n","        # Remove merged boxes\n","        boxes = np.delete(boxes, indices_to_remove, axis=0)\n","\n","        # Append merged box\n","        merged_boxes.append((x1, y1, x2, y2))\n","\n","    return merged_boxes\n","\n","def compute_iou(box1, box2):\n","    \"\"\"\n","    Compute IoU (Intersection over Union) between two bounding boxes.\n","    \"\"\"\n","    x1, y1, x2, y2 = box1\n","    nx1, ny1, nx2, ny2 = box2\n","\n","    # Compute intersection\n","    inter_x1, inter_y1 = max(x1, nx1), max(y1, ny1)\n","    inter_x2, inter_y2 = min(x2, nx2), min(y2, ny2)\n","    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n","\n","    # Compute union\n","    area_box1 = (x2 - x1) * (y2 - y1)\n","    area_box2 = (nx2 - nx1) * (ny2 - ny1)\n","    union_area = area_box1 + area_box2 - inter_area\n","\n","    return inter_area / union_area if union_area > 0 else 0\n","\n","def merge_vertical_boxes(boxes, y_threshold=10):\n","    \"\"\"\n","    Merge vertically close text boxes to form a single bounding box.\n","    \"\"\"\n","    if len(boxes) == 0:\n","        return []\n","\n","    boxes = sorted(boxes, key=lambda x: x[1])\n","\n","    merged_boxes = []\n","    current_box = boxes[0]\n","\n","    for i in range(1, len(boxes)):\n","        x1, y1, x2, y2 = current_box\n","        nx1, ny1, nx2, ny2 = boxes[i]\n","\n","        if abs(ny1 - y2) <= y_threshold:\n","            current_box = (min(x1, nx1), min(y1, ny1), max(x2, nx2), max(y2, ny2))\n","        else:\n","            merged_boxes.append(current_box)\n","            current_box = boxes[i]\n","\n","    merged_boxes.append(current_box)\n","    return merged_boxes\n","\n","def crop_text_regions(image_path, boxes, margin=5):\n","    image = cv2.imread(image_path)\n","    cropped_texts = []\n","    for (x1, y1, x2, y2) in boxes:\n","        x1, y1 = max(0, x1 - margin), max(0, y1 - margin)\n","        x2, y2 = min(image.shape[1], x2 + margin), min(image.shape[0], y2 + margin)\n","        cropped = image[y1:y2, x1:x2]\n","        cropped_texts.append(cropped)\n","    return cropped_texts\n","\n","def extract_text_features():\n","  reader = easyocr.Reader(['en'])\n","  text_features_dict = {}\n","\n","  for folder in os.listdir(CROPS_DIR):\n","      folder_path = os.path.join(CROPS_DIR, folder)\n","      if os.path.isdir(folder_path):\n","          for img_file in os.listdir(folder_path):\n","              img_path = os.path.join(folder_path, img_file)\n","\n","              detected_boxes = detect_text_east(img_path)\n","              merged_boxes = merge_overlapping_boxes(detected_boxes, iou_threshold=0.3)\n","              merged_boxes = merge_vertical_boxes(merged_boxes, y_threshold=15)\n","\n","              cropped_texts = crop_text_regions(img_path, merged_boxes)\n","\n","              text_results = []\n","              for cropped_img in cropped_texts:\n","                  if isinstance(cropped_img, np.ndarray):\n","                      results = reader.readtext(cropped_img)\n","                      for bbox, text, conf in results:\n","                          text_results.append(text)\n","              text_features_dict[img_file] = text_results\n","  np.save(\"text_features.npy\", text_features_dict, allow_pickle=True)\n","\n","def vectorize_text_features():\n","    text_features = np.load(TEXT_FEATURES_FILE, allow_pickle=True).item()\n","    vectorizer = TfidfVectorizer(max_features=50)\n","    text_list = [\" \".join(text_features.get(img, [])) for img in text_features.keys()]\n","    text_vectors = vectorizer.fit_transform(text_list).toarray()\n","    np.save(\"text_features_vectorized.npy\", text_vectors)\n","\n","def combine_all_features():\n","    feature_files = [\"cnn_features.npy\", \"color_features.npy\", \"shape_features.npy\",\n","                     \"texture_features.npy\", \"spatial_features.npy\", \"text_features_vectorized.npy\"]\n","\n","    missing_files = [f for f in feature_files if not os.path.exists(f)]\n","    if missing_files:\n","        print(f\"Missing files: {missing_files}\")\n","        return\n","\n","    cnn_features = np.load(\"cnn_features.npy\", allow_pickle=True).item()\n","    color_features = np.load(\"color_features.npy\", allow_pickle=True).item()\n","    shape_features = np.load(\"shape_features.npy\", allow_pickle=True).item()\n","    texture_features = np.load(\"texture_features.npy\", allow_pickle=True).item()\n","    spatial_features = np.load(\"spatial_features.npy\", allow_pickle=True).item()\n","    text_vectors = np.load(\"text_features_vectorized.npy\")\n","\n","    text_features = np.load(\"text_features.npy\", allow_pickle=True).item()\n","    text_keys = list(text_features.keys())\n","\n","    all_image_keys = (set(cnn_features.keys()) & set(color_features.keys()) &\n","                      set(shape_features.keys()) & set(texture_features.keys()) &\n","                      set(spatial_features.keys()) & set(text_features.keys()))\n","\n","    all_image_keys = sorted(list(all_image_keys))\n","\n","    text_vectors_ordered = [text_vectors[text_keys.index(img)] if img in text_keys else np.zeros((50,)) for img in all_image_keys]\n","\n","\n","    cnn_dim = 2048\n","    color_dim = 512\n","    shape_dim = 7200\n","    texture_dim = 257\n","    spatial_dim = 5\n","    text_dim = 50\n","\n","    combined_features = []\n","    image_names = []\n","\n","    for i, filename in enumerate(all_image_keys):\n","        cnn_feat = cnn_features.get(filename, np.zeros((cnn_dim,)))\n","        color_feat = color_features.get(filename, np.zeros((color_dim,)))\n","        shape_feat = shape_features.get(filename, np.zeros((shape_dim,)))\n","        texture_feat = texture_features.get(filename, np.zeros((texture_dim,)))\n","        spatial_feat = spatial_features.get(filename, np.zeros((spatial_dim,)))\n","        text_feat = text_vectors_ordered[i]\n","\n","        final_feature = np.concatenate([cnn_feat, color_feat, shape_feat, texture_feat, spatial_feat, text_feat])\n","        combined_features.append(final_feature)\n","        image_names.append(filename)\n","\n","    np.save(\"final_combined_features.npy\", np.array(combined_features))\n","\n","    print(\"Feature fusion complete, save as `final_combined_features.npy`\")\n","\n","def combined_all_features_without_text():\n","\n","  cnn_features = np.load(\"cnn_features.npy\", allow_pickle=True).item()\n","  color_features = np.load(\"color_features.npy\", allow_pickle=True).item()\n","  shape_features = np.load(\"shape_features.npy\", allow_pickle=True).item()\n","  texture_features = np.load(\"texture_features.npy\", allow_pickle=True).item()\n","  spatial_features = np.load(\"spatial_features.npy\", allow_pickle=True).item()\n","\n","  all_image_keys = set(cnn_features.keys()) & set(color_features.keys()) & set(shape_features.keys()) & set(texture_features.keys()) & set(spatial_features.keys())\n","\n","  all_image_keys = sorted(list(all_image_keys))\n","\n","  cnn_dim = 2048\n","  color_dim = 512\n","  shape_dim = 7200\n","  texture_dim = 257\n","  spatial_dim = 5\n","\n","  combined_features = []\n","  image_names = []\n","\n","  for filename in all_image_keys:\n","      cnn_feat = cnn_features.get(filename, np.zeros((cnn_dim,)))\n","      color_feat = color_features.get(filename, np.zeros((color_dim,)))\n","      shape_feat = shape_features.get(filename, np.zeros((shape_dim,)))\n","      texture_feat = texture_features.get(filename, np.zeros((texture_dim,)))\n","      spatial_feat = spatial_features.get(filename, np.zeros((spatial_dim,)))\n","\n","      final_feature = np.concatenate([cnn_feat, color_feat, shape_feat, texture_feat, spatial_feat])\n","      combined_features.append(final_feature)\n","      image_names.append(filename)\n","\n","  np.save(\"final_combined_features.npy\", np.array(combined_features))\n","  np.save(\"image_names.npy\", np.array(image_names))\n","\n","  print(\"Sucessfully combine all features\")\n","\n","def normalized_all_features():\n","\n","    cnn_features = np.load(\"cnn_features.npy\", allow_pickle=True).item()\n","    color_features = np.load(\"color_features.npy\", allow_pickle=True).item()\n","    shape_features = np.load(\"shape_features.npy\", allow_pickle=True).item()\n","    texture_features = np.load(\"texture_features.npy\", allow_pickle=True).item()\n","    spatial_features = np.load(\"spatial_features.npy\", allow_pickle=True).item()\n","\n","    all_image_keys = set(cnn_features.keys()) & set(color_features.keys()) & \\\n","                     set(shape_features.keys()) & set(texture_features.keys()) & set(spatial_features.keys())\n","\n","    all_image_keys = sorted(list(all_image_keys))\n","\n","    cnn_dim = 2048\n","    color_dim = 512\n","    shape_dim = 7200\n","    texture_dim = 257\n","    spatial_dim = 5\n","\n","    cnn_data, color_data, shape_data, texture_data, spatial_data = [], [], [], [], []\n","    image_names = []\n","\n","    for filename in all_image_keys:\n","        cnn_data.append(cnn_features.get(filename, np.zeros((cnn_dim,))))\n","        color_data.append(color_features.get(filename, np.zeros((color_dim,))))\n","        shape_data.append(shape_features.get(filename, np.zeros((shape_dim,))))\n","        texture_data.append(texture_features.get(filename, np.zeros((texture_dim,))))\n","        spatial_data.append(spatial_features.get(filename, np.zeros((spatial_dim,))))\n","        image_names.append(filename)\n","\n","    cnn_data = np.array(cnn_data)\n","    color_data = np.array(color_data)\n","    shape_data = np.array(shape_data)\n","    texture_data = np.array(texture_data)\n","    spatial_data = np.array(spatial_data)\n","\n","    scaler = StandardScaler()\n","    cnn_data = scaler.fit_transform(cnn_data)\n","    color_data = scaler.fit_transform(color_data)*2\n","    shape_data = scaler.fit_transform(shape_data)\n","    texture_data = scaler.fit_transform(texture_data)\n","    spatial_data = scaler.fit_transform(spatial_data)*2\n","\n","    np.save(\"cnn_only_features.npy\", cnn_data)\n","    np.save(\"color_only_features.npy\", color_data)\n","    np.save(\"shape_only_features.npy\", shape_data)\n","    np.save(\"texture_only_features.npy\", texture_data)\n","    np.save(\"spatial_only_features.npy\", spatial_data)\n","\n","    np.save(\"image_names.npy\", np.array(image_names))\n","\n","    # Define feature combinations\n","    feature_combinations = [\n","        (np.hstack([color_data, spatial_data]), \"color_spatial_features\"),\n","        (np.hstack([cnn_data, color_data]), \"cnn_color_features\"),\n","        (np.hstack([cnn_data, shape_data]), \"cnn_shape_features\"),\n","        (np.hstack([cnn_data, texture_data]), \"cnn_texture_features\"),\n","        (np.hstack([cnn_data, spatial_data]), \"cnn_spatial_features\"),\n","        (np.hstack([color_data, shape_data]), \"color_shape_features\"),\n","        (np.hstack([color_data, texture_data]), \"color_texture_features\"),\n","        (np.hstack([color_data, spatial_data]), \"color_spatial_features\"),\n","        (np.hstack([cnn_data, color_data, shape_data]), \"cnn_color_shape_features\"),\n","        (np.hstack([cnn_data, color_data, texture_data]), \"cnn_color_texture_features\"),\n","        (np.hstack([cnn_data, color_data, spatial_data]), \"cnn_color_spatial_features\"),\n","        (np.hstack([cnn_data, shape_data, texture_data]), \"cnn_shape_texture_features\"),\n","        (np.hstack([cnn_data, shape_data, spatial_data]), \"cnn_shape_spatial_features\"),\n","        (np.hstack([cnn_data, texture_data, spatial_data]), \"cnn_texture_spatial_features\"),\n","        (np.hstack([cnn_data, color_data, shape_data, texture_data]), \"cnn_color_shape_texture_features\"),\n","        (np.hstack([cnn_data, color_data, shape_data, spatial_data]), \"cnn_color_shape_spatial_features\"),\n","        (np.hstack([color_data, shape_data, texture_data, spatial_data]),\"color_shape_texture_spatial_features\"),\n","        (np.hstack([cnn_data, color_data, shape_data, texture_data, spatial_data]), \"all_features\"),\n","    ]\n","\n","    # Save each combination as a separate .npy file\n","    for features, name in feature_combinations:\n","        np.save(f\"{name}.npy\", features)\n","        print(f\"Saved {name}.npy successfully!\")\n","\n","\n","def normalized_all_features_with_text():\n","\n","    cnn_features = np.load(\"cnn_features.npy\", allow_pickle=True).item()\n","    color_features = np.load(\"color_features.npy\", allow_pickle=True).item()\n","    shape_features = np.load(\"shape_features.npy\", allow_pickle=True).item()\n","    texture_features = np.load(\"texture_features.npy\", allow_pickle=True).item()\n","    spatial_features = np.load(\"spatial_features.npy\", allow_pickle=True).item()\n","    text_features = np.load(\"text_features.npy\", allow_pickle=True).item()\n","    text_vectors = np.load(\"text_features_vectorized.npy\")\n","\n","    text_keys = list(text_features.keys())\n","    all_image_keys = set(cnn_features.keys()) & set(color_features.keys()) & set(shape_features.keys()) & \\\n","                     set(texture_features.keys()) & set(spatial_features.keys()) & set(text_features.keys())\n","    all_image_keys = sorted(list(all_image_keys))\n","\n","    cnn_data, color_data, shape_data, texture_data, spatial_data, text_data = [], [], [], [], [], []\n","    image_names = []\n","\n","    cnn_dim = 2048\n","    color_dim = 512\n","    shape_dim = 7200\n","    texture_dim = 257\n","    spatial_dim = 5\n","    text_dim = 50  # TF-IDF max_features\n","\n","    for i, filename in enumerate(all_image_keys):\n","        cnn_data.append(cnn_features.get(filename, np.zeros((cnn_dim,))))\n","        color_data.append(color_features.get(filename, np.zeros((color_dim,))))\n","        shape_data.append(shape_features.get(filename, np.zeros((shape_dim,))))\n","        texture_data.append(texture_features.get(filename, np.zeros((texture_dim,))))\n","        spatial_data.append(spatial_features.get(filename, np.zeros((spatial_dim,))))\n","        if filename in text_keys:\n","            idx = text_keys.index(filename)\n","            text_data.append(text_vectors[idx])\n","        else:\n","            text_data.append(np.zeros((text_dim,)))\n","        image_names.append(filename)\n","\n","    scaler = StandardScaler()\n","    cnn_data = scaler.fit_transform(cnn_data)\n","    color_data = scaler.fit_transform(color_data) * 2\n","    shape_data = scaler.fit_transform(shape_data)\n","    texture_data = scaler.fit_transform(texture_data)\n","    spatial_data = scaler.fit_transform(spatial_data) * 2\n","    text_data = scaler.fit_transform(text_data)\n","\n","    # Save only TEXT\n","    np.save(\"text_only_features.npy\", text_data)\n","\n","    # Save combinations that include text\n","    np.save(\"cnn_text_features.npy\", np.hstack([cnn_data, text_data]))\n","    np.save(\"cnn_color_text_features.npy\", np.hstack([cnn_data, color_data, text_data]))\n","    np.save(\"all_features_with_text.npy\", np.hstack([cnn_data, color_data, shape_data, texture_data, spatial_data, text_data]))\n","\n","    np.save(\"image_names_with_text.npy\", np.array(image_names))\n","\n","    print(\"Store complete\")\n","\n","\n","def main():\n","    cnn_features_dict = {}\n","    color_features_dict = {}\n","    shape_features_dict = {}\n","    texture_features_dict = {}\n","    for folder in os.listdir(CROPS_DIR):\n","      folder_path = os.path.join(CROPS_DIR, folder)\n","      if os.path.isdir(folder_path):\n","          for img_file in os.listdir(folder_path):\n","              img_path = os.path.join(folder_path, img_file)\n","              img, gray = read_image(img_path)\n","              cnn_features_dict[img_file] = cnn_extract_features(img_path)\n","              color_features_dict[img_file] = extract_color_histogram(img)\n","              shape_features_dict[img_file] = extract_shape_features(gray)\n","              texture_features_dict[img_file] = extract_texture_features(gray)\n","\n","    np.save(\"cnn_features.npy\", cnn_features_dict, allow_pickle=True)\n","    print(\"CNN feature is extracted successfully！\")\n","\n","    np.save(\"color_features.npy\", color_features_dict, allow_pickle=True)\n","    print(\"Color feature is extracted successfully！\")\n","\n","    np.save(\"shape_features.npy\", shape_features_dict, allow_pickle=True)\n","    print(\"Shape feature is extracted successfully！\")\n","\n","    np.save(\"texture_features.npy\", texture_features_dict, allow_pickle=True)\n","    print(\"Texture feature is extracted successfully！\")\n","\n","    extract_spatial_features()\n","\n","    print(\"\\n Running normalized_all_features() (baseline)...\")\n","    normalized_all_features()\n","\n","    print(\"\\n Extracting and vectorizing text features...\")\n","    extract_text_features()\n","    vectorize_text_features()\n","\n","    print(\"\\n Running normalized_all_features_with_text()...\")\n","    normalized_all_features_with_text()\n","\n","    print(\"\\nAll features (with and without text) have been saved.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}