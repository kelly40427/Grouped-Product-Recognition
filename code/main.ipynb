{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":794921,"status":"ok","timestamp":1753468305104,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"CNWUBB1Gsf2z","outputId":"dfbcb8fb-04d9-4a2c-863f-700629646755"},"outputs":[],"source":["%pip install import-ipynb\n","from google.colab import drive\n","import shutil\n","import os\n","from sklearn.cluster import OPTICS\n","import numpy as np\n","from collections import defaultdict, Counter\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score, calinski_harabasz_score\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from scipy.stats import entropy\n","\n","drive.mount('/content/drive')\n","DATASET_CHOICE = \"grozi\" # choose grozi / webmarket\n","GROUND_TRUTH_CHOICE = \"grozi\" # choose grozi / webmarket/ real\n","REAL_IMAGE_MODE = False # if Dutch Markets -> True, else then False\n","\n","# ============================================\n","# Load YOLO Detection & Features\n","# ============================================\n","%run \"/content/drive/MyDrive/Object_Recognition/detect_yolo.ipynb\"\n","%run \"/content/drive/MyDrive/Object_Recognition/feature_extraction.ipynb\""]},{"cell_type":"markdown","metadata":{"id":"VcxtfafUaRKS"},"source":["## Ground truth dataset setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4970,"status":"ok","timestamp":1753468565235,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"bmUWHuIrBqYY","outputId":"f5177ac4-c2da-47e6-e53c-cc24adc5d83e"},"outputs":[],"source":["# ----- Ground Truth Dataset Setup -----\n","if GROUND_TRUTH_CHOICE == \"webmarket\":\n","    gt_dataset_path = \"/content/datasets/Webmarket-5\"\n","    gt_labels_folder = os.path.join(gt_dataset_path, \"test/labels\")\n","    if not os.path.exists(gt_dataset_path):\n","        rf = Roboflow(api_key=\"ILw5ia3CDLaVSgIHRYon\")\n","        project = rf.workspace(\"final-project-mwyx2\").project(\"webmarket-7inwv-e4bky\")\n","        version = project.version(6)\n","        dataset = version.download(\"yolov5\")\n","    else:\n","        print(\"Webmarket GT dataset already exists.\")\n","elif GROUND_TRUTH_CHOICE == \"grozi\":\n","    gt_dataset_path = \"/content/datasets/grozi-3.2k-testing-6\"\n","    gt_labels_folder = os.path.join(gt_dataset_path, \"test/labels\")\n","    if not os.path.exists(gt_dataset_path):\n","        rf = Roboflow(api_key=\"ILw5ia3CDLaVSgIHRYon\")\n","        project = rf.workspace(\"final-project-mwyx2\").project(\"grozi-3.2k-testing-fzu9s\")\n","        version = project.version(7)\n","        dataset = version.download(\"yolov5\")\n","    else:\n","        print(\"Grozi GT dataset already exists.\")\n","elif GROUND_TRUTH_CHOICE == \"real\":\n","    gt_dataset_path = \"/content/datasets/Dutch-supermarket-grocery-2\"\n","    gt_labels_folder = os.path.join(gt_dataset_path, \"test/labels\")\n","    if not os.path.exists(gt_dataset_path):\n","        rf = Roboflow(api_key=\"ILw5ia3CDLaVSgIHRYon\")\n","        project = rf.workspace(\"final-project-mwyx2\").project(\"dutch-supermarket-grocery\")\n","        version = project.version(2)\n","        dataset = version.download(\"yolov5\")\n","    else:\n","        print(\"Real GT dataset already exists.\")\n","\n","else:\n","    raise ValueError(\"Unsupported ground truth dataset.\")\n","\n","print(\"Ground Truth Labels Folder:\", gt_labels_folder)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":105,"status":"ok","timestamp":1753468576055,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"aQ3SyJFeHwbL"},"outputs":[],"source":["# ============================================\n","# 5. Clustering Functions\n","# ============================================\n","\n","def optics_clustering(feature_file, image_name_file, xi, min_samples=2, min_cluster_size=None):\n","    \"\"\"\n","    Parameter:\n","    - min_samples (int): The number of samples in a neighborhood for a point to be considered as a core point. Also, up and down steep regions\n","       can’t have more than min_samples consecutive non-steep points.\n","    - xi (float): Determines the minimum steepness on the reachability plot that constitutes a cluster boundary.\n","    - min_cluster_size (int): Minimum number of samples in an OPTICS cluster, expressed as an absolute number or a fraction of the number of\n","      samples (rounded to be at least 2). If None, the value of min_samples is used instead. Used only when cluster_method='xi'.\n","\n","    Return:\n","    - cluster_results (dict): dict: {Original_image_name: {cropped_image_name: cluster_label}})\n","    \"\"\"\n","\n","    # Read `.npy` file\n","    features = np.load(feature_file)\n","    image_names = np.load(image_name_file)\n","\n","    image_groups = defaultdict(list)\n","    feature_groups = defaultdict(list)\n","\n","    for i, img_name in enumerate(image_names):\n","        base_name = img_name.split(\"_jpg\")[0]  # get orinigal image name, ex: \"175\"  #\"_jpg\" (use in webmarket and grocery_product) \"_\" (used in real)\n","        image_groups[base_name].append(img_name)\n","        feature_groups[base_name].append(features[i])\n","\n","    cluster_results = {}\n","\n","    for base_name, feature_list in feature_groups.items():\n","        features_array = np.array(feature_list)\n","\n","        # If Cropped Images less than 2，then it's not possible to do Clustering，directly noted as Cluster 0\n","        if len(features_array) < 2:\n","            cluster_labels = [0] * len(features_array)\n","        else:\n","            features_scaled = features_array\n","\n","            # Using OPTICS\n","            print(f\"Image {base_name} using OPTICS clustering...\")\n","            model = OPTICS(min_samples=min_samples, xi=xi, min_cluster_size=min_cluster_size)\n","            cluster_labels = model.fit_predict(features_scaled)\n","\n","        # Save the results\n","        cluster_results[base_name] = dict(zip(image_groups[base_name], cluster_labels))\n","\n","    # Store the results to \".npy\"\n","    np.save(\"per_image_optics_cluster_labels.npy\", cluster_results)\n","\n","    print(\"Clustering Complete, results saved to `per_image_optics_cluster_labels.npy`！\")\n","    return cluster_results\n","\n","def agglomerative_clustering(feature_file, image_name_file, distance_threshold):\n","    \"\"\"\n","    Parameters:\n","    - distance_threshold (float): The linkage distance threshold at or above which clusters will not be merged.\n","      If not None, n_clusters must be None and compute_full_tree must be True.\n","\n","    Return:\n","    - cluster_results (dict): Results of Agglomerative Clustering: dict: {Original_image_name: {cropped_image_name: cluster_label}})\n","    \"\"\"\n","\n","    # Read `.npy` file\n","    features = np.load(feature_file)\n","    image_names = np.load(image_name_file)\n","\n","    image_groups = defaultdict(list)\n","    feature_groups = defaultdict(list)\n","\n","    for i, img_name in enumerate(image_names):\n","        base_name = img_name.split(\"_jpg\")[0] #\"_jpg\" (use in webmarket and grocery_product) \"_\"(used in real)\n","        image_groups[base_name].append(img_name)\n","        feature_groups[base_name].append(features[i])\n","\n","    cluster_results = {}\n","\n","    for base_name, feature_list in feature_groups.items():\n","        features_array = np.array(feature_list)\n","\n","        if len(features_array) < 2:\n","            cluster_labels = [0] * len(features_array)\n","        else:\n","            print(f\"Image {base_name} using Agglomerative Clustering...\")\n","\n","            # Using Agglomerative Clustering\n","            model = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold, linkage='ward')\n","            cluster_labels = model.fit_predict(features_array)\n","\n","        # Save the results\n","        cluster_results[base_name] = dict(zip(image_groups[base_name], cluster_labels))\n","\n","    # Store the results to \".npy\"\n","    np.save(\"per_image_agglo_cluster_labels.npy\", cluster_results)\n","\n","    print(\"Agglomerative Clustering Complete, results saved to `per_image_agglo_cluster_labels.npy`！\")\n","    return cluster_results\n","\n","# ============================================\n","# 4. Utility Functions\n","# ============================================\n","def load_yolo_gt(gt_label_folder):\n","    \"\"\"\n","    Read YOLOv5 ground truth to {image_name: [bbox information]}\n","    \"\"\"\n","    gt_data = {}\n","\n","    for label_file in os.listdir(gt_label_folder):\n","        image_name = label_file.replace(\".txt\", \".jpg\")\n","        label_path = os.path.join(gt_label_folder, label_file)\n","\n","        with open(label_path, \"r\") as f:\n","            gt_bboxes = []\n","            for line in f:\n","                parts = line.strip().split()\n","                class_id = int(parts[0])  # Ground turth label\n","                bbox = list(map(float, parts[1:]))  # bbox: [x_center, y_center, width, height]\n","                gt_bboxes.append((class_id, bbox))\n","\n","        gt_data[image_name] = gt_bboxes\n","\n","    return gt_data\n","\n","def get_bbox_from_cropped_image(cropped_img_name):\n","    \"\"\"\n","    Based on cropped image name to get bounding box ([x_center, y_center, width, height])\n","    \"\"\"\n","    if cropped_img_name in spatial_features:\n","        return spatial_features[cropped_img_name][:4]  # Get first four value: [x_center, y_center, width, height]\n","    else:\n","        return None\n","\n","def compute_iou(box1, box2):\n","    \"\"\"\n","    Compute IoU (Intersection over Union) between ground truth bounding boxes and predicted bounding boxes.\n","    box = [x_center, y_center, width, height]\n","    \"\"\"\n","\n","    # Convert YOLO format to (x_min, y_min, x_max, y_max)\n","    x1_min, y1_min = box1[0] - box1[2] / 2, box1[1] - box1[3] / 2\n","    x1_max, y1_max = box1[0] + box1[2] / 2, box1[1] + box1[3] / 2\n","\n","    x2_min, y2_min = box2[0] - box2[2] / 2, box2[1] - box2[3] / 2\n","    x2_max, y2_max = box2[0] + box2[2] / 2, box2[1] + box2[3] / 2\n","\n","    # Compute intersection\n","    inter_x_min = max(x1_min, x2_min)\n","    inter_y_min = max(y1_min, y2_min)\n","    inter_x_max = min(x1_max, x2_max)\n","    inter_y_max = min(y1_max, y2_max)\n","\n","    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n","\n","    # Compute union\n","    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n","    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n","    union_area = box1_area + box2_area - inter_area\n","\n","    # Compute IoU\n","    iou = inter_area / union_area if union_area > 0 else 0\n","    return iou\n","\n","def match_predictions_to_gt(spatial_features, gt_base_grouped, iou_threshold=0.4):\n","    \"\"\"\n","    Match cropped images (predictions) to ground truth objects based on IoU.\n","    \"\"\"\n","    matched_results = {}\n","\n","    for cropped_img_name, pred_bbox in spatial_features.items():\n","        base_name = cropped_img_name.split(\"_jpg\")[0]  # Extract base name\n","\n","        if base_name not in gt_base_grouped:\n","            matched_results[cropped_img_name] = -1  # No GT available\n","            continue\n","\n","        gt_bboxes = gt_base_grouped[base_name]  # Get ground truth bboxes for this image\n","        best_match = -1\n","        best_iou = 0.0\n","\n","        for gt_class, gt_bbox in gt_bboxes:\n","            iou = compute_iou(pred_bbox[:4], gt_bbox)  # Compare bounding boxes\n","\n","            if iou > best_iou and iou >= iou_threshold:\n","                best_iou = iou\n","                best_match = gt_class  # Assign ground truth class\n","\n","        matched_results[cropped_img_name] = best_match  # Store match\n","\n","    return matched_results\n","\n","def compute_per_image_cluster_to_gt_mapping(cluster_results, matched_results, min_cluster_size=2):\n","    \"\"\"\n","    - If Cluster size is less than one：\n","      - If GT Label only appears once, the Remap（Clustering correct）。\n","      - If GT Label has multiple samples in the original image，then annotate Clustering incorrect (`-1`)。\n","    -\n","    \"\"\"\n","    per_image_cluster_gt_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n","    cluster_sizes = defaultdict(lambda: defaultdict(int))\n","    gt_label_counts = defaultdict(lambda: defaultdict(int))\n","\n","    # Compute the number of GT Label in each Cluster & Cluster Size\n","    for base_name, cropped_images in cluster_results.items():\n","        for cropped_img, cluster_id in cropped_images.items():\n","            if cropped_img not in matched_results or matched_results[cropped_img] == -1:\n","                continue  # If cropped image doesn't match GT in IoU Matching, then pass\n","\n","            gt_label = matched_results[cropped_img]\n","\n","            per_image_cluster_gt_counts[base_name][cluster_id][gt_label] += 1\n","            cluster_sizes[base_name][cluster_id] += 1\n","            gt_label_counts[base_name][gt_label] += 1  # Count the number of GT Label in original image\n","\n","    per_image_cluster_to_gt_mapping = {}\n","\n","    for base_name, cluster_dict in per_image_cluster_gt_counts.items():\n","        per_image_cluster_to_gt_mapping[base_name] = {}\n","\n","        for cluster_id, gt_count in cluster_dict.items():\n","            if cluster_id == -1:\n","                  per_image_cluster_to_gt_mapping[base_name][cluster_id] = -1 # Deak with noise cluster（cluster_id == -1）\n","                  continue\n","            cluster_size = cluster_sizes[base_name][cluster_id]\n","            best_gt_label = max(gt_count, key=gt_count.get)  # Most frequent GT Label in that cluster\n","\n","            if cluster_size < min_cluster_size:\n","                # Check the number of GT Label in that orignial image\n","                gt_label_total_count = gt_label_counts[base_name][best_gt_label]\n","\n","                if gt_label_total_count > 1:\n","                    # If this GT Label has multiple other samples in this original image, then marked as misclassified\n","                    per_image_cluster_to_gt_mapping[base_name][cluster_id] = -1\n","                else:\n","                    # If this GT Label in the original image only appears \"once\"，then allowed to Remap\n","                    per_image_cluster_to_gt_mapping[base_name][cluster_id] = best_gt_label\n","            else:\n","                # Choose the most frequent GT Label to cluster label\n","                per_image_cluster_to_gt_mapping[base_name][cluster_id] = best_gt_label\n","\n","    return per_image_cluster_to_gt_mapping\n","\n","def evaluate_clustering(cluster_results, matched_results, cluster_to_gt_mapping, features_all_path, image_names_path):\n","\n","    y_true = []  # Ground Truth Labels\n","    y_pred = []  # Predicted Cluster Labels\n","    y_pred_raw = []  # Original cluster id，does not remap GT，used in silhouette（keep -1）\n","    image_names_flat = []\n","\n","    # Covert Clustering Label and GT Label\n","    for base_name, cropped_images in cluster_results.items():\n","        if base_name not in cluster_to_gt_mapping:\n","            continue  # If this original images does not have the corresponding mapping，then pass\n","\n","        for cropped_img, cluster_id in cropped_images.items():\n","            if cropped_img in matched_results and matched_results[cropped_img] != -1:\n","                gt_label = matched_results[cropped_img]  #  GT Label of this cropped images\n","                pred_label = cluster_to_gt_mapping[base_name].get(cluster_id, -1)  # Predicted Label of this cluster\n","\n","                y_true.append(gt_label)\n","                y_pred.append(pred_label)\n","                y_pred_raw.append(cluster_id)\n","                image_names_flat.append(cropped_img)\n","\n","    # Compute Adjusted Rand Index (ARI)\n","    ari = adjusted_rand_score(y_true, y_pred)\n","\n","    # Compute Normalized Mutual Information (NMI)\n","    nmi = normalized_mutual_info_score(y_true, y_pred)\n","\n","    # Compute Silhouette\n","    try:\n","        features_all = np.load(features_all_path)\n","        image_names = np.load(image_names_path)\n","\n","        if isinstance(image_names[0], bytes):\n","            image_names = np.array([n.decode(\"utf-8\") for n in image_names])\n","        image_name_list = image_names.tolist()\n","\n","        used_indices = []\n","        for name in image_names_flat:\n","            if name in image_name_list:\n","                idx = image_name_list.index(name)\n","                used_indices.append(idx)\n","\n","        selected_features = features_all[used_indices]\n","\n","        # Silhouette (all)\n","        silhouette_all = -1\n","        if len(set(y_pred_raw)) > 1:\n","            silhouette_all = silhouette_score(selected_features, y_pred_raw)\n","\n","        # Silhouette (clean)\n","        features_filtered = [f for f, cid in zip(selected_features, y_pred_raw) if cid != -1]\n","        preds_filtered = [cid for cid in y_pred_raw if cid != -1]\n","        silhouette_clean = -1\n","        if len(set(preds_filtered)) > 1:\n","            silhouette_clean = silhouette_score(features_filtered, preds_filtered)\n","\n","    except Exception as e:\n","      print(f\"Error computing clustering metrics: {e}\")\n","      ari = -1\n","      nmi = -1\n","      silhouette = -1\n","\n","    return ari, nmi, silhouette_all, silhouette_clean\n","\n","spatial_features = np.load(\"spatial_features.npy\", allow_pickle=True).item()\n","ground_truth = load_yolo_gt(gt_labels_folder)\n","\n","# Convert GT to Base Name Mapping**\n","gt_base_grouped = {}\n","\n","for full_img_name, gt_objects in ground_truth.items():\n","    base_name = full_img_name.split(\"_jpg\")[0]  # Extract base name\n","\n","    if base_name not in gt_base_grouped:\n","        gt_base_grouped[base_name] = []\n","\n","    gt_base_grouped[base_name].extend(gt_objects)  # Append GT objects\n","\n","# Perform IoU-based matching\n","matched_results = match_predictions_to_gt(spatial_features, gt_base_grouped, iou_threshold=0.4)\n","\n","# Save results\n","np.save(\"matched_results.npy\", matched_results)\n"]},{"cell_type":"markdown","metadata":{"id":"2Ip8EFqjKK3A"},"source":["## Fixed threshold selection"]},{"cell_type":"markdown","metadata":{"id":"wieNDvu4TkKC"},"source":["\n","\n","*   Agglomerative Clustering\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193260,"status":"ok","timestamp":1753469067301,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"70Mh0N_rB1hI","outputId":"397ca28d-fc64-4678-9c93-fc7e69bdd39e"},"outputs":[],"source":["ari_results = defaultdict(list)\n","nmi_results = defaultdict(list)\n","silhouette_results = defaultdict(list)\n","# 定義特徵組合與檔案\n","feature_files = {\n","    \"cnn\": \"cnn_only_features.npy\",\n","    \"color\": \"color_only_features.npy\",\n","    \"shape\": \"shape_only_features.npy\",\n","    \"texture\": \"texture_only_features.npy\",\n","    \"spatial\": \"spatial_only_features.npy\",\n","    \"text\": \"text_only_features.npy\",\n","    \"cnn_color\": \"cnn_color_features.npy\",\n","    \"cnn_shape\": \"cnn_shape_features.npy\",\n","    \"cnn_texture\": \"cnn_texture_features.npy\",\n","    \"cnn_spatial\": \"cnn_spatial_features.npy\",\n","    \"cnn_text\": \"cnn_text_features.npy\",\n","    \"color_shape\": \"color_shape_features.npy\",\n","    \"color_texture\": \"color_texture_features.npy\",\n","    \"color_spatial\": \"color_spatial_features.npy\",\n","    \"cnn_color_shape\": \"cnn_color_shape_features.npy\",\n","    \"cnn_color_texture\": \"cnn_color_texture_features.npy\",\n","    \"cnn_color_spatial\": \"cnn_color_spatial_features.npy\",\n","    \"cnn_color_text\":\"cnn_color_text_features.npy\",\n","    \"cnn_shape_texture\": \"cnn_shape_texture_features.npy\",\n","    \"cnn_shape_spatial\": \"cnn_shape_spatial_features.npy\",\n","    \"cnn_texture_spatial\": \"cnn_texture_spatial_features.npy\",\n","    \"cnn_color_shape_texture\": \"cnn_color_shape_texture_features.npy\",\n","    \"cnn_color_shape_spatial\": \"cnn_color_shape_spatial_features.npy\",\n","    \"color_shape_texture_spatial\": \"color_shape_texture_spatial_features.npy\",\n","    \"cnn_color_shape_texture_spatial\": \"all_features.npy\",\n","    \"cnn_color_shape_texture_spatial_text\": \"all_features_with_text.npy\"\n","}\n","\n","distance_thresholds = list(range(30, 161, 5))\n","matched_results = np.load(\"matched_results.npy\", allow_pickle=True).item()\n","# # Run each threshold + differnt combined feature\n","for feature_name, feature_path in feature_files.items():\n","    print(f\"\\n Combined Feature: {feature_name}\")\n","\n","    if \"text\" in feature_name:\n","        image_name_file = \"image_names_with_text.npy\"\n","    else:\n","        image_name_file = \"image_names.npy\"\n","\n","    for threshold in distance_thresholds:\n","        print(f\"threshold = {threshold}\")\n","        try:\n","            cluster_results = agglomerative_clustering(feature_path, image_name_file, threshold)\n","            cluster_to_gt = compute_per_image_cluster_to_gt_mapping(cluster_results, matched_results)\n","            ari, nmi, _, silhouette = evaluate_clustering(cluster_results, matched_results, cluster_to_gt, feature_path, image_name_file)\n","        except Exception as e:\n","            print(f\"Error at feature {feature_name}, threshold {threshold}: {e}\")\n","            ari = -1\n","            nmi = -1\n","            silhouette = -1\n","        ari_results[feature_name].append(ari)\n","        nmi_results[feature_name].append(nmi)\n","        silhouette_results[feature_name].append(silhouette)\n","\n","# Save as DataFrame and CSV\n","ari_df = pd.DataFrame(ari_results, index=distance_thresholds)\n","ari_df.index.name = \"Distance Threshold\"\n","ari_df.to_csv(\"ari_across_thresholds.csv\")\n","print(\"Save to ari_across_thresholds.csv\")\n","\n","nmi_df = pd.DataFrame(nmi_results, index=distance_thresholds)\n","nmi_df.index.name = \"Distance Threshold\"\n","nmi_df.to_csv(\"nmi_across_thresholds.csv\")\n","\n","silhouette_df = pd.DataFrame(silhouette_results, index=distance_thresholds)\n","silhouette_df.index.name = \"Distance Threshold\"\n","silhouette_df.to_csv(\"silhouette_across_thresholds.csv\")\n","\n","# Show best Thresholds\n","best_thresholds_ari = ari_df.idxmax()\n","best_aris = ari_df.max()\n","\n","best_thresholds_nmi = nmi_df.idxmax()\n","best_nmis = nmi_df.max()\n","\n","best_thresholds_silhouette = silhouette_df.idxmax()\n","best_silhouettes = silhouette_df.max()\n","\n","print(\"Best Thresholds by Metric - Agglomerative\")\n","for feat in ari_df.columns:\n","    print(f\"\\nFeature Combination: {feat}\")\n","    print(f\"  ARI      -> {best_aris[feat]:.4f}\")\n","    print(f\"  NMI      -> {best_nmis[feat]:.4f}\")\n","    print(f\"  Silhouette-> {best_silhouettes[feat]:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"S4Xafmp4TpJY"},"source":["\n","\n","*   OPTICS\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275718,"status":"ok","timestamp":1753395371089,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"netslogtHS3C","outputId":"94008353-c7bd-4e36-d9d3-ae38a51fcb28"},"outputs":[],"source":["ari_results_optics = defaultdict(list)\n","nmi_results_optics = defaultdict(list)\n","silhouette_results_optics = defaultdict(list)\n","\n","xi_thresholds = [i / 100 for i in range(1, 11)] # [0.01, 0.02, ..., 0.10]\n","# Run each threshold + differnt combined features\n","for feature_name, feature_path in feature_files.items():\n","    print(f\"\\n Combined Feature: {feature_name}\")\n","\n","    if \"text\" in feature_name:\n","        image_name_file = \"image_names_with_text.npy\"\n","    else:\n","        image_name_file = \"image_names.npy\"\n","    for threshold in xi_thresholds:\n","        print(f\"threshold = {threshold}\")\n","        try:\n","            cluster_results_optics = optics_clustering(feature_path, image_name_file, threshold)\n","            cluster_to_gt_optics = compute_per_image_cluster_to_gt_mapping(cluster_results_optics, matched_results)\n","            ari_optics, nmi_optics, _, silhouette_optics  = evaluate_clustering(cluster_results_optics, matched_results, cluster_to_gt_optics, feature_path, image_name_file)\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            ari_optics = -1\n","        ari_results_optics[feature_name].append(ari_optics)\n","        nmi_results_optics[feature_name].append(nmi_optics)\n","        silhouette_results_optics[feature_name].append(silhouette_optics)\n","\n","\n","ari_optics_df = pd.DataFrame(ari_results_optics, index=xi_thresholds)\n","nmi_optics_df = pd.DataFrame(nmi_results_optics, index=xi_thresholds)\n","silhouette_optics_df = pd.DataFrame(silhouette_results_optics, index=xi_thresholds)\n","\n","ari_optics_df.index.name = \"Xi Threshold\"\n","nmi_optics_df.index.name = \"Xi Threshold\"\n","silhouette_optics_df.index.name = \"Xi Threshold\"\n","\n","ari_optics_df.to_csv(\"ari_across_thresholds_optics.csv\")\n","nmi_optics_df.to_csv(\"nmi_across_thresholds_optics.csv\")\n","silhouette_optics_df.to_csv(\"silhouette_across_thresholds_optics.csv\")\n","\n","best_thresholds_ari = ari_optics_df.idxmax()\n","best_aris = ari_optics_df.max()\n","\n","best_thresholds_nmi = nmi_optics_df.idxmax()\n","best_nmis = nmi_optics_df.max()\n","\n","best_thresholds_silhouette = silhouette_optics_df.idxmax()\n","best_silhouettes = silhouette_optics_df.max()\n","\n","print(\"Best Xi Thresholds by Metric - OPTICS\")\n","for feat in ari_optics_df.columns:\n","    print(f\"\\nFeature Combination: {feat}\")\n","    print(f\"  ARI      -> {best_aris[feat]:.4f}\")\n","    print(f\"  NMI      -> {best_nmis[feat]:.4f}\")\n","    print(f\"  Silhouette-> {best_silhouettes[feat]:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"D1f43TC5TumG"},"source":["## Threshold optimaization selection"]},{"cell_type":"markdown","metadata":{"id":"hOri_n_vT4ea"},"source":["### Silhouette Score selection"]},{"cell_type":"markdown","metadata":{"id":"jiulMhN4UAdW"},"source":["\n","\n","*   Agglomerative Clustering\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79574,"status":"ok","timestamp":1753395675647,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"_YkbYC8tDXuN","outputId":"60b00b0f-6303-4b45-854b-55141bf24745"},"outputs":[],"source":["def agglomerative_clustering_auto_threshold_silhouette(feature_file, image_name_file, threshold_candidates, visualize=True):\n","    features = np.load(feature_file)\n","    image_names = np.load(image_name_file)\n","\n","    image_groups = defaultdict(list)\n","    feature_groups = defaultdict(list)\n","\n","    for i, img_name in enumerate(image_names):\n","        base_name = img_name.split(\"_jpg\")[0]\n","        image_groups[base_name].append(img_name)\n","        feature_groups[base_name].append(features[i])\n","\n","    cluster_results = {}\n","\n","    for base_name, feature_list in feature_groups.items():\n","        features_array = np.array(feature_list)\n","\n","        if len(features_array) < 2:\n","            cluster_labels = [0] * len(features_array)\n","        else:\n","            print(f\"Image {base_name} - Running Agglomerative Clustering with multiple thresholds...\")\n","\n","            silhouette_scores = []\n","            valid_thresholds = []\n","            label_candidates = []\n","\n","            for threshold in threshold_candidates:\n","                try:\n","                    model = AgglomerativeClustering(n_clusters=None, distance_threshold=threshold, linkage='ward')\n","                    labels = model.fit_predict(features_array)\n","\n","                    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n","                    if n_clusters <= 1 or n_clusters >= len(features_array):\n","                        continue\n","\n","                    score = silhouette_score(features_array, labels)\n","                    silhouette_scores.append(score)\n","                    valid_thresholds.append(threshold)\n","                    label_candidates.append(labels)\n","                except Exception as e:\n","                    continue\n","\n","            if not valid_thresholds:\n","                print(f\"Image {base_name} - No valid clustering found, fallback to single cluster.\")\n","                cluster_labels = [0] * len(features_array)\n","            else:\n","                idx = np.argmax(silhouette_scores)\n","                best_threshold = valid_thresholds[idx]\n","                cluster_labels = label_candidates[idx]\n","\n","                print(f\"Image {base_name} - Best threshold selected: {best_threshold} with Silhouette Score {silhouette_scores[idx]:.4f}\")\n","\n","                if visualize:\n","                    plt.figure()\n","                    plt.plot(valid_thresholds, silhouette_scores, 'bo-')\n","                    plt.xlabel('Distance Threshold')\n","                    plt.ylabel('Silhouette Score')\n","                    plt.title(f'Silhouette Curve - {base_name}')\n","                    plt.axvline(x=best_threshold, color='red', linestyle='--')\n","                    plt.grid()\n","                    plt.show()\n","\n","        cluster_results[base_name] = dict(zip(image_groups[base_name], cluster_labels))\n","\n","    np.save(\"per_image_agglo_silhouette_cluster_labels.npy\", cluster_results)\n","    print(\"Agglomerative Clustering complete. Results saved to `per_image_agglo_silhouette_cluster_labels.npy`！\")\n","    return cluster_results\n","\n","\n","feature_files = {\n","    \"cnn\": \"cnn_only_features.npy\",\n","    \"color\": \"color_only_features.npy\",\n","    \"shape\": \"shape_only_features.npy\",\n","    \"texture\": \"texture_only_features.npy\",\n","    \"spatial\": \"spatial_only_features.npy\",\n","    \"text\": \"text_only_features.npy\",\n","    \"cnn_color\": \"cnn_color_features.npy\",\n","    \"cnn_shape\": \"cnn_shape_features.npy\",\n","    \"cnn_texture\": \"cnn_texture_features.npy\",\n","    \"cnn_spatial\": \"cnn_spatial_features.npy\",\n","    \"cnn_text\": \"cnn_text_features.npy\",\n","    \"color_shape\": \"color_shape_features.npy\",\n","    \"color_texture\": \"color_texture_features.npy\",\n","    \"color_spatial\": \"color_spatial_features.npy\",\n","    \"cnn_color_shape\": \"cnn_color_shape_features.npy\",\n","    \"cnn_color_texture\": \"cnn_color_texture_features.npy\",\n","    \"cnn_color_spatial\": \"cnn_color_spatial_features.npy\",\n","    \"cnn_color_text\":\"cnn_color_text_features.npy\",\n","    \"cnn_shape_texture\": \"cnn_shape_texture_features.npy\",\n","    \"cnn_shape_spatial\": \"cnn_shape_spatial_features.npy\",\n","    \"cnn_texture_spatial\": \"cnn_texture_spatial_features.npy\",\n","    \"cnn_color_shape_texture\": \"cnn_color_shape_texture_features.npy\",\n","    \"cnn_color_shape_spatial\": \"cnn_color_shape_spatial_features.npy\",\n","    \"color_shape_texture_spatial\": \"color_shape_texture_spatial_features.npy\",\n","    \"cnn_color_shape_texture_spatial\": \"all_features.npy\",\n","    \"cnn_color_shape_texture_spatial_text\": \"all_features_with_text.npy\"\n","}\n","\n","results_summary = []\n","\n","for feature_key, feature_path in feature_files.items():\n","    print(f\"\\n=== Processing Feature Set: {feature_key} ===\")\n","\n","    if \"text\" in feature_key:\n","        image_name_file = \"image_names_with_text.npy\"\n","    else:\n","        image_name_file = \"image_names.npy\"\n","\n","    cluster_results = agglomerative_clustering_auto_threshold_silhouette(\n","        feature_file=feature_path,\n","        image_name_file=image_name_file,\n","        threshold_candidates=np.linspace(20, 200, num=30), # distance threshold range\n","        visualize=False\n","    )\n","    cluster_to_gt_mapping = compute_per_image_cluster_to_gt_mapping(cluster_results, matched_results)\n","\n","    ari, nmi, sil_all, sil_clean = evaluate_clustering(\n","        cluster_results,\n","        matched_results,\n","        cluster_to_gt_mapping,\n","        features_all_path=feature_path,\n","        image_names_path=image_name_file\n","    )\n","\n","    results_summary.append({\n","        \"feature\": feature_key,\n","        \"ARI\": ari,\n","        \"NMI\": nmi,\n","        \"Silhouette_All\": sil_all,\n","        \"Silhouette_Clean\": sil_clean\n","    })\n","\n","df_results = pd.DataFrame(results_summary)\n","# Save to CSV\n","df_results.to_csv(\"clustering_evaluation_summary.csv\", index=False)\n","\n","# Print preview\n","print(df_results.to_string(index=False))"]},{"cell_type":"markdown","metadata":{"id":"CkhKlk3IUKrF"},"source":["*   OPTICS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":627043,"status":"ok","timestamp":1753397248574,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"0671tfo2NOfy","outputId":"5090a9f7-79e8-4ade-c7e6-7091b1c15aba"},"outputs":[],"source":["def optics_clustering_auto_xi_silhouette(feature_file, image_name_file, xi_candidates, visualize=True):\n","    features = np.load(feature_file)\n","    image_names = np.load(image_name_file)\n","\n","    image_groups = defaultdict(list)\n","    feature_groups = defaultdict(list)\n","\n","    for i, img_name in enumerate(image_names):\n","        base_name = img_name.split(\"_jpg\")[0]\n","        image_groups[base_name].append(img_name)\n","        feature_groups[base_name].append(features[i])\n","\n","    cluster_results = {}\n","\n","    for base_name, feature_list in feature_groups.items():\n","        features_array = np.array(feature_list)\n","\n","        if len(features_array) < 2:\n","            cluster_labels = [0] * len(features_array)\n","        else:\n","            print(f\"Image {base_name} - Running OPTICS Clustering with multiple xi...\")\n","\n","            silhouette_scores = []\n","            valid_xi = []\n","            label_candidates = []\n","\n","            for xi in xi_candidates:\n","                try:\n","                    model = OPTICS(min_samples=2, xi=xi)\n","                    labels = model.fit_predict(features_array)\n","\n","                    unique_labels = set(labels)\n","                    if len(unique_labels) <= 1 or len(unique_labels) >= len(features_array):\n","                        continue\n","\n","                    score = silhouette_score(features_array, labels)\n","                    silhouette_scores.append(score)\n","                    valid_xi.append(xi)\n","                    label_candidates.append(labels)\n","                except Exception as e:\n","                    continue\n","\n","            if not valid_xi:\n","                print(f\"Image {base_name} - No valid xi produced meaningful clusters. Fallback to single cluster.\")\n","                cluster_labels = [0] * len(features_array)\n","            else:\n","                idx = np.argmax(silhouette_scores)\n","                best_xi = valid_xi[idx]\n","                cluster_labels = label_candidates[idx]\n","\n","                print(f\"Image {base_name} - Best xi: {best_xi} with Silhouette Score {silhouette_scores[idx]:.4f}\")\n","\n","                if visualize:\n","                    plt.figure()\n","                    plt.plot(valid_xi, silhouette_scores, 'go-')\n","                    plt.xlabel('xi')\n","                    plt.ylabel('Silhouette Score')\n","                    plt.title(f'Silhouette Curve (OPTICS) - {base_name}')\n","                    plt.axvline(x=best_xi, color='red', linestyle='--')\n","                    plt.grid()\n","                    plt.show()\n","\n","        cluster_results[base_name] = dict(zip(image_groups[base_name], cluster_labels))\n","\n","    np.save(\"per_image_optics_silhouette_cluster_labels.npy\", cluster_results)\n","    print(\"OPTICS Clustering complete. Results saved to `per_image_optics_silhouette_cluster_labels.npy`！\")\n","    return cluster_results\n","\n","results_summary_optics = []\n","xi_candidates = np.linspace(0.01, 0.2, 20) # xi_threshold range\n","\n","for feature_key, feature_path in feature_files.items():\n","    print(f\"\\n=== Processing Feature Set: {feature_key} ===\")\n","\n","    if \"text\" in feature_key:\n","        image_name_file = \"image_names_with_text.npy\"\n","    else:\n","        image_name_file = \"image_names.npy\"\n","\n","    cluster_results = optics_clustering_auto_xi_silhouette(\n","            feature_file=feature_path,\n","            image_name_file=image_name_file,\n","            xi_candidates=xi_candidates,\n","            visualize=False\n","        )\n","    cluster_to_gt_mapping = compute_per_image_cluster_to_gt_mapping(cluster_results, matched_results)\n","\n","    ari, nmi, sil_all, sil_clean = evaluate_clustering(\n","        cluster_results,\n","        matched_results,\n","        cluster_to_gt_mapping,\n","        features_all_path=feature_path,\n","        image_names_path=image_name_file\n","    )\n","\n","    results_summary_optics.append({\n","        \"feature\": feature_key,\n","        \"ARI\": ari,\n","        \"NMI\": nmi,\n","        \"Silhouette_All\": sil_all,\n","        \"Silhouette_Clean\": sil_clean\n","    })\n","\n","df_results = pd.DataFrame(results_summary_optics)\n","# Save to CSV\n","df_results.to_csv(\"optics_clustering_evaluation_summary.csv\", index=False)\n","\n","# Print preview\n","print(df_results.to_string(index=False))"]},{"cell_type":"markdown","metadata":{"id":"T96XW2n-Uchr"},"source":["### Entropy selection"]},{"cell_type":"markdown","metadata":{"id":"u5CnvWx0U3OH"},"source":["\n","\n","*   Agglomerative Clustering\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41351,"status":"ok","timestamp":1753397289934,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"eJMvZCRDONkU","outputId":"30b91eb7-50ed-454e-fd1e-1cb744c20d2e"},"outputs":[],"source":["def compute_internal_entropy(labels):\n","    from collections import Counter\n","    label_counts = Counter(labels)\n","    total = sum(label_counts.values())\n","    probs = np.array(list(label_counts.values())) / total\n","    return entropy(probs, base=2)\n","\n","def agglomerative_clustering_auto_threshold_entropy(feature_file, image_name_file, matched_results, threshold_candidates, visualize=False):\n","    features = np.load(feature_file)\n","    image_names = np.load(image_name_file)\n","\n","    image_groups = defaultdict(list)\n","    feature_groups = defaultdict(list)\n","    gt_label_groups = defaultdict(list)\n","\n","    for i, img_name in enumerate(image_names):\n","        base_name = img_name.split(\"_jpg\")[0]\n","        image_groups[base_name].append(img_name)\n","        feature_groups[base_name].append(features[i])\n","\n","        gt = matched_results.get(img_name, -1)\n","        gt_label_groups[base_name].append(gt)\n","\n","    cluster_results = {}\n","\n","    for base_name in feature_groups:\n","        features_array = np.array(feature_groups[base_name])\n","        gt_labels = gt_label_groups[base_name]\n","\n","        if len(features_array) < 2 or all(l == -1 for l in gt_labels):\n","            cluster_labels = [0] * len(features_array)\n","        else:\n","            entropies = []\n","            thresholds = []\n","            label_candidates = []\n","\n","            for threshold in threshold_candidates:\n","                try:\n","                    model = AgglomerativeClustering(n_clusters=None, distance_threshold=threshold, linkage='ward')\n","                    labels = model.fit_predict(features_array)\n","\n","                    if len(set(labels)) <= 1 or len(set(labels)) >= len(features_array):\n","                        continue\n","\n","                    e_score = compute_internal_entropy(labels)\n","\n","                    entropies.append(e_score)\n","                    thresholds.append(threshold)\n","                    label_candidates.append(labels)\n","                except:\n","                    continue\n","\n","            if not entropies:\n","                cluster_labels = [0] * len(features_array)\n","            else:\n","                best_idx = np.argmin(entropies)\n","                cluster_labels = label_candidates[best_idx]\n","\n","                if visualize:\n","                    plt.figure()\n","                    plt.plot(thresholds, entropies, 'go-')\n","                    plt.xlabel(\"Threshold\")\n","                    plt.ylabel(\"Entropy\")\n","                    plt.title(f\"Entropy Curve - {base_name}\")\n","                    plt.axvline(x=thresholds[best_idx], color='red', linestyle='--')\n","                    plt.grid()\n","                    plt.show()\n","\n","        cluster_results[base_name] = dict(zip(image_groups[base_name], cluster_labels))\n","\n","    return cluster_results\n","\n","# ----- ENTROPY Clustering evaluation -----\n","matched_results = np.load(\"matched_results.npy\", allow_pickle=True).item()\n","feature_files = {\n","    \"cnn\": \"cnn_only_features.npy\",\n","    \"color\": \"color_only_features.npy\",\n","    \"shape\": \"shape_only_features.npy\",\n","    \"texture\": \"texture_only_features.npy\",\n","    \"spatial\": \"spatial_only_features.npy\",\n","    \"text\": \"text_only_features.npy\",\n","    \"cnn_color\": \"cnn_color_features.npy\",\n","    \"cnn_shape\": \"cnn_shape_features.npy\",\n","    \"cnn_texture\": \"cnn_texture_features.npy\",\n","    \"cnn_spatial\": \"cnn_spatial_features.npy\",\n","    \"cnn_text\": \"cnn_text_features.npy\",\n","    \"color_shape\": \"color_shape_features.npy\",\n","    \"color_texture\": \"color_texture_features.npy\",\n","    \"color_spatial\": \"color_spatial_features.npy\",\n","    \"cnn_color_shape\": \"cnn_color_shape_features.npy\",\n","    \"cnn_color_texture\": \"cnn_color_texture_features.npy\",\n","    \"cnn_color_spatial\": \"cnn_color_spatial_features.npy\",\n","    \"cnn_color_text\":\"cnn_color_text_features.npy\",\n","    \"cnn_shape_texture\": \"cnn_shape_texture_features.npy\",\n","    \"cnn_shape_spatial\": \"cnn_shape_spatial_features.npy\",\n","    \"cnn_texture_spatial\": \"cnn_texture_spatial_features.npy\",\n","    \"cnn_color_shape_texture\": \"cnn_color_shape_texture_features.npy\",\n","    \"cnn_color_shape_spatial\": \"cnn_color_shape_spatial_features.npy\",\n","    \"color_shape_texture_spatial\": \"color_shape_texture_spatial_features.npy\",\n","    \"cnn_color_shape_texture_spatial\": \"all_features.npy\",\n","    \"cnn_color_shape_texture_spatial_text\": \"all_features_with_text.npy\"\n","}\n","\n","results_summary = []\n","\n","# entropy-based clustering evaluation for different feature combinations\n","for feature_key, feature_path in feature_files.items():\n","    print(f\"\\n Processing Feature Set: {feature_key}\")\n","    image_name_file = \"image_names_with_text.npy\" if \"text\" in feature_key else \"image_names.npy\"\n","\n","    cluster_results = agglomerative_clustering_auto_threshold_entropy(\n","        feature_file=feature_path,\n","        image_name_file=image_name_file,\n","        matched_results=matched_results,\n","        threshold_candidates=np.linspace(20, 200, num=30),\n","        visualize=False\n","    )\n","\n","    cluster_to_gt_mapping = compute_per_image_cluster_to_gt_mapping(cluster_results, matched_results)\n","\n","    # Evaluation\n","    ari, nmi, sil_all, sil_clean = evaluate_clustering(\n","        cluster_results,\n","        matched_results,\n","        cluster_to_gt_mapping,\n","        features_all_path=feature_path,\n","        image_names_path=image_name_file\n","    )\n","\n","    results_summary.append({\n","        \"feature\": feature_key,\n","        \"ARI\": ari,\n","        \"NMI\": nmi,\n","        \"Silhouette_All\": sil_all,\n","        \"Silhouette_Clean\": sil_clean\n","    })\n","\n","# Print the output\n","df_entropy_results = pd.DataFrame(results_summary)\n","print(df_entropy_results.to_string(index=False))"]},{"cell_type":"markdown","metadata":{"id":"PhMliByTU8Kn"},"source":["*   OPTICS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408180,"status":"ok","timestamp":1753397981938,"user":{"displayName":"黃馨慧","userId":"14269854679530396130"},"user_tz":-120},"id":"D4lm6caGU1B2","outputId":"adc4dfb5-2194-472f-9576-d08f51d04ac9"},"outputs":[],"source":["def compute_internal_entropy(labels):\n","    from collections import Counter\n","    label_counts = Counter(labels)\n","    total = sum(label_counts.values())\n","    probs = np.array(list(label_counts.values())) / total\n","    return entropy(probs, base=2)\n","\n","def optics_clustering_auto_xi_entropy(feature_file, image_name_file, matched_results, xi_candidates, min_samples=2):\n","    features = np.load(feature_file)\n","    image_names = np.load(image_name_file)\n","\n","    if isinstance(image_names[0], bytes):\n","        image_names = np.array([n.decode(\"utf-8\") for n in image_names])\n","\n","    image_groups = defaultdict(list)\n","    feature_groups = defaultdict(list)\n","\n","    for i, img_name in enumerate(image_names):\n","        base_name = img_name.split(\"_jpg\")[0]\n","        image_groups[base_name].append(img_name)\n","        feature_groups[base_name].append(features[i])\n","\n","    cluster_results = {}\n","\n","    for base_name in feature_groups:\n","        feats = np.array(feature_groups[base_name])\n","        if len(feats) < 2:\n","            cluster_labels = [0] * len(feats)\n","            cluster_results[base_name] = dict(zip(image_groups[base_name], cluster_labels))\n","            continue\n","\n","        best_entropy = float(\"inf\")\n","        best_labels = None\n","\n","        for xi in xi_candidates:\n","            try:\n","                model = OPTICS(min_samples=min_samples, xi=xi)\n","                labels = model.fit_predict(feats)\n","                valid_labels = [lbl for lbl in labels if lbl != -1]\n","                if len(set(valid_labels)) <= 1:\n","                    continue\n","                e_score = compute_internal_entropy(valid_labels)\n","                if e_score < best_entropy:\n","                    best_entropy = e_score\n","                    best_labels = labels\n","            except:\n","                continue\n","\n","        if best_labels is None:\n","            best_labels = [0] * len(feats)\n","\n","        cluster_results[base_name] = dict(zip(image_groups[base_name], best_labels))\n","\n","    return cluster_results\n","\n","# ----- ENTROPY Clustering Evaluation -----\n","matched_results = np.load(\"matched_results.npy\", allow_pickle=True).item()\n","\n","results_summary = []\n","\n","# entropy-based clustering evaluation for different feature combinations\n","for feature_key, feature_path in feature_files.items():\n","    print(f\"\\n Processing Feature Set: {feature_key}\")\n","    image_name_file = \"image_names_with_text.npy\" if \"text\" in feature_key else \"image_names.npy\"\n","\n","    cluster_results = optics_clustering_auto_xi_entropy(\n","    feature_file=feature_path,\n","    image_name_file=image_name_file,\n","    matched_results=matched_results,\n","    xi_candidates=np.linspace(0.01, 0.2, 20)\n","    )\n","\n","    cluster_to_gt_mapping = compute_per_image_cluster_to_gt_mapping(cluster_results, matched_results)\n","\n","    # Evaluation\n","    ari, nmi, sil_all, sil_clean = evaluate_clustering(\n","        cluster_results,\n","        matched_results,\n","        cluster_to_gt_mapping,\n","        features_all_path=feature_path,\n","        image_names_path=image_name_file\n","    )\n","\n","    results_summary.append({\n","        \"feature\": feature_key,\n","        \"ARI\": ari,\n","        \"NMI\": nmi,\n","        \"Silhouette_All\": sil_all,\n","        \"Silhouette_Clean\": sil_clean\n","    })\n","\n","# Print the result\n","df_entropy_results = pd.DataFrame(results_summary)\n","print(df_entropy_results.to_string(index=False))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOczChaIN6EDVBZmW8HWlb8","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
